#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DDIM vs DDPM å¯¹æ¯”æµ‹è¯•è„šæœ¬
æ¯”è¾ƒä¸¤ç§æ¨¡å‹åœ¨ CIFAR-10 å’Œ CelebA æ•°æ®é›†ä¸Šçš„ç”Ÿæˆæ•ˆæœ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import torch
import torchvision
import torchvision.transforms as T
from torchvision.datasets import CIFAR10, ImageFolder
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import time

from models.ddpm import DDPM_Model
from models.ddim import DDIM_Model

# è®¾ç½®è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

class ModelComparison:
    def __init__(self):
        self.device = device
        self.results = {}
        
    def load_cifar10_models(self):
        """åŠ è½½ CIFAR-10 æ¨¡å‹"""
        print("æ­£åœ¨åŠ è½½ CIFAR-10 æ¨¡å‹...")
        
        # å‡†å¤‡ CIFAR-10 æ•°æ®åŠ è½½å™¨
        transform = T.Compose([
            T.ToTensor(),
            T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        dataset = CIFAR10(root='./data', train=True, download=False, transform=transform)
        dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)
        
        # åŠ è½½ DDPM æ¨¡å‹
        try:
            self.ddpm_cifar = DDPM_Model(dataloader)
            if os.path.exists("../../diffusion_model_cifar.pth"):
                self.ddpm_cifar.load_state_dict(torch.load("../../diffusion_model_cifar.pth", map_location=device))
                print("âœ… DDPM CIFAR-10 æ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                print("âš ï¸ æœªæ‰¾åˆ° DDPM CIFAR-10 æ¨¡å‹æƒé‡æ–‡ä»¶")
                self.ddpm_cifar = None
        except Exception as e:
            print(f"âŒ DDPM CIFAR-10 æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.ddpm_cifar = None
            
        # åŠ è½½ DDIM æ¨¡å‹
        try:
            self.ddim_cifar = DDIM_Model(dataloader, device=device)
            if os.path.exists("../../ddim_model_cifar.pth"):
                self.ddim_cifar.load_state_dict(torch.load("../../ddim_model_cifar.pth", map_location=device))
                print("âœ… DDIM CIFAR-10 æ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                print("âš ï¸ æœªæ‰¾åˆ° DDIM CIFAR-10 æ¨¡å‹æƒé‡æ–‡ä»¶")
                self.ddim_cifar = None
        except Exception as e:
            print(f"âŒ DDIM CIFAR-10 æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.ddim_cifar = None
    
    def load_celeba_models(self):
        """åŠ è½½ CelebA æ¨¡å‹"""
        print("æ­£åœ¨åŠ è½½ CelebA æ¨¡å‹...")
        
        # å‡†å¤‡ CelebA æ•°æ®åŠ è½½å™¨
        transform = T.Compose([
            T.CenterCrop(178),
            T.Resize((64, 64)),
            T.ToTensor(),
            T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        
        if os.path.exists('./data/celeba'):
            dataset = ImageFolder(root='./data/celeba', transform=transform)
            dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)
        else:
            print("âš ï¸ æœªæ‰¾åˆ° CelebA æ•°æ®é›†ï¼Œä½¿ç”¨è™šæ‹Ÿæ•°æ®åŠ è½½å™¨")
            dataloader = None
        
        # åŠ è½½ DDPM CelebA æ¨¡å‹
        try:
            if dataloader:
                self.ddpm_celeba = DDPM_Model(dataloader)
            else:
                self.ddpm_celeba = None
            if os.path.exists("../../diffusion_model_celeba.pth"):
                if self.ddpm_celeba:
                    self.ddpm_celeba.load_state_dict(torch.load("../../diffusion_model_celeba.pth", map_location=device))
                print("âœ… DDPM CelebA æ¨¡å‹æƒé‡æ–‡ä»¶æ‰¾åˆ°")
            else:
                print("âš ï¸ æœªæ‰¾åˆ° DDPM CelebA æ¨¡å‹æƒé‡æ–‡ä»¶")
                self.ddpm_celeba = None
        except Exception as e:
            print(f"âŒ DDPM CelebA æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.ddpm_celeba = None
            
        # åŠ è½½ DDIM CelebA æ¨¡å‹
        try:
            if dataloader:
                self.ddim_celeba = DDIM_Model(dataloader, device=device)
            else:
                self.ddim_celeba = None
            if os.path.exists("../../ddim_model_celeba.pth"):
                if self.ddim_celeba:
                    self.ddim_celeba.load_state_dict(torch.load("../../ddim_model_celeba.pth", map_location=device))
                print("âœ… DDIM CelebA æ¨¡å‹æƒé‡æ–‡ä»¶æ‰¾åˆ°")
            else:
                print("âš ï¸ æœªæ‰¾åˆ° DDIM CelebA æ¨¡å‹æƒé‡æ–‡ä»¶")
                self.ddim_celeba = None
        except Exception as e:
            print(f"âŒ DDIM CelebA æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.ddim_celeba = None

    def generate_samples(self, model, model_type, dataset_name, num_samples=8, ddim_steps=50):
        """ç”Ÿæˆæ ·æœ¬å¹¶è®°å½•æ—¶é—´"""
        if model is None:
            print(f"âš ï¸ {model_type} {dataset_name} æ¨¡å‹ä¸å¯ç”¨ï¼Œç”Ÿæˆéšæœºæ ·æœ¬")
            if dataset_name == "CIFAR-10":
                return torch.randn(num_samples, 3, 32, 32), 0.0
            else:  # CelebA
                return torch.randn(num_samples, 3, 64, 64), 0.0
        
        print(f"æ­£åœ¨ç”Ÿæˆ {model_type} {dataset_name} æ ·æœ¬...")
        start_time = time.time()
        
        try:
            with torch.no_grad():
                if model_type == "DDPM":
                    if dataset_name == "CIFAR-10":
                        samples = model.sample(num_samples, "cifar")
                    else:  # CelebA
                        samples = model.sample(num_samples, "celeba")
                else:  # DDIM
                    if dataset_name == "CIFAR-10":
                        samples = model.sample(num_samples, ddim_steps=ddim_steps)
                    else:  # CelebA
                        # ä¸º CelebA é‡å†™é‡‡æ ·æ–¹æ³•
                        shape = (num_samples, 3, 64, 64)
                        samples = model.p_sample_loop(shape, ddim_steps=ddim_steps)
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ ·æœ¬æ—¶å‡ºé”™: {e}")
            if dataset_name == "CIFAR-10":
                return torch.randn(num_samples, 3, 32, 32), 0.0
            else:
                return torch.randn(num_samples, 3, 64, 64), 0.0
        
        end_time = time.time()
        generation_time = end_time - start_time
        
        return samples.cpu(), generation_time

    def create_comparison_grid(self):
        """åˆ›å»ºå¯¹æ¯”ç½‘æ ¼å›¾åƒ"""
        print("æ­£åœ¨åˆ›å»ºå¯¹æ¯”ç½‘æ ¼...")
        
        # ç”Ÿæˆæ‰€æœ‰æ ·æœ¬
        samples_data = {}
        
        # CIFAR-10 æ ·æœ¬
        if self.ddpm_cifar or self.ddim_cifar:
            ddpm_cifar_samples, ddpm_cifar_time = self.generate_samples(
                self.ddpm_cifar, "DDPM", "CIFAR-10", num_samples=8)
            ddim_cifar_samples, ddim_cifar_time = self.generate_samples(
                self.ddim_cifar, "DDIM", "CIFAR-10", num_samples=8, ddim_steps=50)
            
            samples_data["CIFAR-10"] = {
                "DDPM": (ddpm_cifar_samples, ddpm_cifar_time),
                "DDIM": (ddim_cifar_samples, ddim_cifar_time)
            }
        
        # CelebA æ ·æœ¬
        if self.ddpm_celeba or self.ddim_celeba:
            ddpm_celeba_samples, ddpm_celeba_time = self.generate_samples(
                self.ddpm_celeba, "DDPM", "CelebA", num_samples=8)
            ddim_celeba_samples, ddim_celeba_time = self.generate_samples(
                self.ddim_celeba, "DDIM", "CelebA", num_samples=8, ddim_steps=50)
            
            samples_data["CelebA"] = {
                "DDPM": (ddpm_celeba_samples, ddpm_celeba_time),
                "DDIM": (ddim_celeba_samples, ddim_celeba_time)
            }
        
        # åˆ›å»ºå›¾åƒç½‘æ ¼
        self.create_visual_comparison(samples_data)
    
    def create_visual_comparison(self, samples_data):
        """åˆ›å»ºå¯è§†åŒ–å¯¹æ¯”å›¾"""
        # è®¾ç½®å›¾åƒå¤§å°å’Œå¸ƒå±€
        fig_width = 16
        fig_height = 12
        fig, axes = plt.subplots(4, 8, figsize=(fig_width, fig_height))
        fig.suptitle('DDPM vs DDIM ç”Ÿæˆæ•ˆæœå¯¹æ¯”', fontsize=20, fontweight='bold')
        
        row_labels = []
        datasets = list(samples_data.keys())
        
        current_row = 0
        
        for dataset in datasets:
            for model_type in ["DDPM", "DDIM"]:
                if model_type in samples_data[dataset]:
                    samples, gen_time = samples_data[dataset][model_type]
                    
                    # æ·»åŠ è¡Œæ ‡ç­¾
                    row_labels.append(f"{dataset}\n{model_type}\n({gen_time:.1f}s)")
                    
                    # æ˜¾ç¤º8ä¸ªæ ·æœ¬
                    for col in range(8):
                        ax = axes[current_row, col]
                        
                        if col < samples.shape[0]:
                            # åå½’ä¸€åŒ–å›¾åƒ
                            img = samples[col]
                            img = (img + 1) / 2  # ä» [-1,1] åˆ° [0,1]
                            img = torch.clamp(img, 0, 1)
                            
                            # è½¬æ¢ä¸º numpy å¹¶è°ƒæ•´ç»´åº¦
                            img_np = img.permute(1, 2, 0).numpy()
                            
                            ax.imshow(img_np)
                        else:
                            ax.axis('off')
                        
                        ax.set_xticks([])
                        ax.set_yticks([])
                        
                        # æ·»åŠ åˆ—æ ‡é¢˜ï¼ˆä»…ç¬¬ä¸€è¡Œï¼‰
                        if current_row == 0:
                            ax.set_title(f'æ ·æœ¬ {col+1}', fontsize=10)
                    
                    current_row += 1
        
        # æ·»åŠ è¡Œæ ‡ç­¾
        for i, label in enumerate(row_labels):
            axes[i, 0].set_ylabel(label, rotation=0, labelpad=80, 
                                  fontsize=12, ha='right', va='center')
        
        # éšè—æœªä½¿ç”¨çš„å­å›¾
        for i in range(current_row, 4):
            for j in range(8):
                axes[i, j].axis('off')
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.93, left=0.15)
        
        # ä¿å­˜å›¾åƒ
        output_path = "../../ddim_vs_ddpm_comparison.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"âœ… å¯¹æ¯”å›¾åƒå·²ä¿å­˜ä¸º: {output_path}")
        
        # æ˜¾ç¤ºå›¾åƒ
        plt.show()
        
        return output_path
    
    def run_comparison(self):
        """è¿è¡Œå®Œæ•´çš„å¯¹æ¯”æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ DDIM vs DDPM å¯¹æ¯”æµ‹è¯•")
        print("=" * 50)
        
        # åŠ è½½æ¨¡å‹
        self.load_cifar10_models()
        self.load_celeba_models()
        
        print("\n" + "=" * 50)
        print("ğŸ“Š ç”Ÿæˆå¯¹æ¯”æ ·æœ¬...")
        
        # åˆ›å»ºå¯¹æ¯”ç½‘æ ¼
        self.create_comparison_grid()
        
        print("\n" + "=" * 50)
        print("ğŸ‰ å¯¹æ¯”æµ‹è¯•å®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    print("DDIM vs DDPM æ•ˆæœå¯¹æ¯”æµ‹è¯•")
    print("æœ¬è„šæœ¬å°†å¯¹æ¯”ä¸¤ç§æ‰©æ•£æ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„ç”Ÿæˆæ•ˆæœ")
    print("è¯·ç¡®ä¿å·²æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡æ–‡ä»¶")
    print("-" * 60)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_files = [
        "../../diffusion_model_cifar.pth",
        "../../ddim_model_cifar.pth", 
        "../../diffusion_model_celeba.pth",
        "../../ddim_model_celeba.pth"
    ]
    
    print("ğŸ“ æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
    for file in model_files:
        if os.path.exists(file):
            print(f"âœ… {file}")
        else:
            print(f"âš ï¸ {file} (ä¸å­˜åœ¨)")
    
    print("\n" + "-" * 60)
    
    # è¿è¡Œå¯¹æ¯”
    comparison = ModelComparison()
    comparison.run_comparison()

if __name__ == "__main__":
    main() 