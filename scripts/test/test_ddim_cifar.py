#!/usr/bin/env python3
"""
DDIM CIFAR-10 æ¨¡å‹æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¸åŒé‡‡æ ·æ–¹æ³•çš„æ•ˆæœå’Œæ—¶é—´
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import torch
import torchvision
import torchvision.transforms as T
import os
import matplotlib.pyplot as plt
import numpy as np
from models.ddim import DDIM_Model

def create_comparison_grid(model_path="../../ddim_model_cifar.pth", num_samples=4, output_path="../../ddim_step_comparison.png"):
    """
    åˆ›å»ºå±•ç¤ºä¸åŒæ­¥æ•°é‡‡æ ·è´¨é‡å˜åŒ–çš„å¯¹æ¯”å›¾
    åŒ…å«åˆå§‹å™ªå£°å’Œå››ä¸ªä¸åŒæ­¥æ•°çš„é‡‡æ ·ç»“æœ
    
    Args:
        model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        num_samples: æ¯ç§é…ç½®çš„æ ·æœ¬æ•°é‡
        output_path: è¾“å‡ºå¯¹æ¯”å›¾è·¯å¾„
    """
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè¿è¡Œ train_ddim_cifar.py è®­ç»ƒæ¨¡å‹")
        return
    
    class FakeDataset(torch.utils.data.Dataset):
        def __getitem__(self, index):
            return torch.randn(3, 32, 32), 0
        def __len__(self):
            return num_samples
            
    dataloader = torch.utils.data.DataLoader(FakeDataset(), batch_size=num_samples)

    # åŠ è½½ DDIM æ¨¡å‹
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    model = DDIM_Model(dataloader, device=device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    
    # ç”Ÿæˆåˆå§‹å™ªå£°å›¾åƒ
    torch.manual_seed(42)  # å›ºå®šéšæœºç§å­ç¡®ä¿å¯å¤ç°æ€§
    initial_noise = torch.randn(num_samples, 3, 32, 32).to(device)
    
    # é‡‡æ ·é…ç½®
    sampling_configs = [
        {"name": "20 step", "steps": 20, "eta": 0.0},
        {"name": "50 step", "steps": 50, "eta": 0.0},
        {"name": "100 step", "steps": 100, "eta": 0.0},
        {"name": "50 step(random)", "steps": 50, "eta": 0.5}
    ]
    
    # å­˜å‚¨æ‰€æœ‰ç”Ÿæˆçš„å›¾åƒ
    all_images = []
    all_titles = []
    
    # æ·»åŠ åˆå§‹å™ªå£°
    all_images.append(initial_noise.cpu())
    all_titles.append("Initial Noise")
    
    print("å¼€å§‹ç”Ÿæˆä¸åŒæ­¥æ•°çš„é‡‡æ ·å¯¹æ¯”...")
    
    with torch.no_grad():
        for config in sampling_configs:
            print(f"ç”Ÿæˆ {config['name']} é‡‡æ ·...")
            
            # ä½¿ç”¨ç›¸åŒçš„åˆå§‹å™ªå£°
            torch.manual_seed(42)
            
            # ç”Ÿæˆæ ·æœ¬
            if hasattr(model, 'p_sample_loop'):
                shape = (num_samples, 3, 32, 32)
                samples = model.p_sample_loop(shape, ddim_steps=config["steps"], eta=config["eta"])
            else:
                samples = model.sample(num_samples, ddim_steps=config["steps"], eta=config["eta"])
            
            all_images.append(samples.cpu())
            all_titles.append(f"{config['name']}")
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    fig, axes = plt.subplots(len(all_images), num_samples, figsize=(num_samples * 3, len(all_images) * 3))
    fig.suptitle('DDIM Sampling Quality Evolution', fontsize=16, fontweight='bold')
    
    for row_idx, (images, title) in enumerate(zip(all_images, all_titles)):
        for col_idx in range(num_samples):
            ax = axes[row_idx, col_idx] if num_samples > 1 else axes[row_idx]
            
            # è½¬æ¢å›¾åƒæ ¼å¼ç”¨äºæ˜¾ç¤º
            img = images[col_idx]
            img = torch.clamp((img + 1) / 2, 0, 1)  # ä» [-1,1] è½¬æ¢åˆ° [0,1]
            img = img.permute(1, 2, 0).numpy()
            
            ax.imshow(img)
            ax.axis('off')
            
            # åªåœ¨ç¬¬ä¸€åˆ—æ·»åŠ è¡Œæ ‡é¢˜
            if col_idx == 0:
                ax.text(-0.1, 0.5, title, transform=ax.transAxes, 
                       rotation=90, va='center', ha='center', fontsize=12, fontweight='bold')
            
            # åªåœ¨ç¬¬ä¸€è¡Œæ·»åŠ åˆ—æ ‡é¢˜
            if row_idx == 0:
                ax.set_title(f'Sample {col_idx + 1}', fontsize=10)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")
    print("å¯¹æ¯”å›¾å±•ç¤ºäº†ä»åˆå§‹å™ªå£°åˆ°ä¸åŒæ­¥æ•°é‡‡æ ·çš„è´¨é‡å˜åŒ–è¿‡ç¨‹")

def test_cifar_ddim(model_path="../../ddim_model_cifar.pth", num_samples=16, output_prefix="ddim_cifar_test"):
    """
    æµ‹è¯• DDIM CIFAR-10 æ¨¡å‹ï¼Œç”Ÿæˆå¤šç§é‡‡æ ·é…ç½®çš„æ ·æœ¬
    
    Args:
        model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        num_samples: ç”Ÿæˆæ ·æœ¬æ•°é‡
        output_prefix: è¾“å‡ºæ–‡ä»¶å‰ç¼€
    """
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè¿è¡Œ train_ddim_cifar.py è®­ç»ƒæ¨¡å‹")
        return
    
    class FakeDataset(torch.utils.data.Dataset):
        def __getitem__(self, index):
            # è¿”å›ä¸æ¨¡å‹è¾“å…¥åŒ¹é…çš„éšæœºå¼ é‡
            return torch.randn(3, 32, 32), 0
        def __len__(self):
            return num_samples
            
    dataloader = torch.utils.data.DataLoader(FakeDataset(), batch_size=num_samples)

    # åŠ è½½ DDIM æ¨¡å‹
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    model = DDIM_Model(dataloader, device=device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    
    print(f"å¼€å§‹ç”Ÿæˆ {num_samples} ä¸ªæ ·æœ¬...")

    # æµ‹è¯•ä¸åŒçš„ DDIM é‡‡æ ·é…ç½®
    sampling_configs = [
        {"name": "fast", "steps": 200, "eta": 0.0, "desc": "fast (200 step)"},
        {"name": "standard", "steps": 500, "eta": 0.0, "desc": "standard (500 step)"},
        {"name": "high_quality", "steps": 1000, "eta": 0.0, "desc": "high quality (100 step)"},
        {"name": "stochastic", "steps": 50, "eta": 0.5, "desc": "stochastic (500 step, eta=0.5)"}
    ]
    
    with torch.no_grad():
        for config in sampling_configs:
            print(f"ç”Ÿæˆ {config['desc']}...")
            
            # ç”Ÿæˆæ ·æœ¬
            if hasattr(model, 'p_sample_loop'):
                # ä½¿ç”¨ p_sample_loop æ–¹æ³•
                shape = (num_samples, 3, 32, 32)
                samples = model.p_sample_loop(shape, ddim_steps=config["steps"], eta=config["eta"])
            else:
                # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨ sample æ–¹æ³•
                samples = model.sample(num_samples, ddim_steps=config["steps"], eta=config["eta"])
            
            # ä¿å­˜å›¾åƒ
            output_path = f"{output_prefix}_{config['name']}.png"
            torchvision.utils.save_image(samples, output_path, nrow=4, normalize=True, value_range=(-1, 1))
            print(f"âœ… å·²ä¿å­˜: {output_path}")
    
    print("\nğŸ‰ DDIM CIFAR-10 æµ‹è¯•å®Œæˆ!")
    print("ç”Ÿæˆçš„å›¾åƒæ–‡ä»¶:")
    for config in sampling_configs:
        print(f"  - {output_prefix}_{config['name']}.png ({config['desc']})")

def compare_ddim_speeds(model_path="../../ddim_model_cifar.pth", num_samples=8):
    """
    å¯¹æ¯”ä¸åŒ DDIM æ­¥æ•°çš„ç”Ÿæˆé€Ÿåº¦
    """
    import time
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    class FakeDataset(torch.utils.data.Dataset):
        def __getitem__(self, index):
            return torch.randn(3, 32, 32), 0
        def __len__(self):
            return num_samples
            
    dataloader = torch.utils.data.DataLoader(FakeDataset(), batch_size=num_samples)
    
    model = DDIM_Model(dataloader, device=device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    
    print("\nâ±ï¸  DDIM é€Ÿåº¦å¯¹æ¯”æµ‹è¯•:")
    print("=" * 40)
    
    step_configs = [10, 20, 50, 100, 200, 500]
    shape = (num_samples, 3, 32, 32)
    
    with torch.no_grad():
        for steps in step_configs:
            start_time = time.time()
            
            if hasattr(model, 'p_sample_loop'):
                samples = model.p_sample_loop(shape, ddim_steps=steps, eta=0.0)
            else:
                samples = model.sample(num_samples, ddim_steps=steps, eta=0.0)
            
            end_time = time.time()
            elapsed = end_time - start_time
            
            print(f"{steps:3d} æ­¥: {elapsed:.2f} ç§’ ({elapsed/num_samples:.3f} ç§’/å›¾)")

if __name__ == "__main__":
    # åˆ›å»ºæ­¥æ•°å¯¹æ¯”å›¾
    print("åˆ›å»º DDIM æ­¥æ•°è´¨é‡å¯¹æ¯”å›¾...")
    create_comparison_grid()
    
    print("\n" + "="*50)
    
    # åŸºæœ¬æµ‹è¯•
    test_cifar_ddim()
    
    # é€Ÿåº¦å¯¹æ¯”æµ‹è¯•
    print("\n" + "="*50)
    compare_ddim_speeds() 