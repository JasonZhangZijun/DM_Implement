#!/usr/bin/env python3
"""
ç»Ÿä¸€çš„è®­ç»ƒå’Œè¯„ä¼°è„šæœ¬

åŠŸèƒ½ï¼š
- æ”¯æŒ CIFAR-10 å’Œ CelebA æ•°æ®é›†
- è®­ç»ƒ DDPM å’Œæ¡ä»¶ DDPM æ¨¡å‹
- è‡ªåŠ¨ç”Ÿæˆæ ·æœ¬å’Œè¯„ä¼° FID
- ä¿å­˜æ¨¡å‹å’Œå®éªŒç»“æœ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import argparse
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torchvision import transforms
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime
import json

from config import get_config
from models.ddpm import DDPM_Model
from models.conditional_ddpm import ConditionalDDPM_Model
from inpaint_ddpm import InpaintDDPM
from utils.fid import evaluate_generated_images
from utils.losses import psnr, ssim

class ExperimentLogger:
    """å®éªŒæ—¥å¿—è®°å½•å™¨"""
    def __init__(self, log_dir):
        self.log_dir = log_dir
        os.makedirs(log_dir, exist_ok=True)
        self.log_file = os.path.join(log_dir, "experiment.log")
        self.metrics_file = os.path.join(log_dir, "metrics.json")
        self.metrics = {}
    
    def log(self, message):
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_message = f"[{timestamp}] {message}"
        print(log_message)
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(log_message + "\n")
    
    def save_metrics(self, epoch, metrics_dict):
        if epoch not in self.metrics:
            self.metrics[epoch] = {}
        self.metrics[epoch].update(metrics_dict)
        
        with open(self.metrics_file, "w", encoding="utf-8") as f:
            json.dump(self.metrics, f, indent=2, ensure_ascii=False)

class DataLoaderFactory:
    """æ•°æ®åŠ è½½å™¨å·¥å‚"""
    @staticmethod
    def get_cifar10_loader(config):
        transform = transforms.Compose([
            transforms.Resize((config.image_size, config.image_size)),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        
        dataset = torchvision.datasets.CIFAR10(
            root=config.data_path,
            train=True,
            download=True,
            transform=transform
        )
        
        return torch.utils.data.DataLoader(
            dataset,
            batch_size=config.batch_size,
            shuffle=True,
            num_workers=config.num_workers,
            drop_last=True
        )
    
    @staticmethod
    def get_test_loader(config):
        transform = transforms.Compose([
            transforms.Resize((config.image_size, config.image_size)),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        
        dataset = torchvision.datasets.CIFAR10(
            root=config.data_path,
            train=False,
            download=True,
            transform=transform
        )
        
        return torch.utils.data.DataLoader(
            dataset,
            batch_size=config.batch_size,
            shuffle=False,
            num_workers=config.num_workers
        )

def save_samples(samples, save_path, nrow=8):
    """ä¿å­˜ç”Ÿæˆçš„æ ·æœ¬"""
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    # å°†æ ·æœ¬ä»[-1, 1]è½¬æ¢åˆ°[0, 1]
    samples = (samples + 1) / 2
    samples = torch.clamp(samples, 0, 1)
    
    # ä¿å­˜å›¾åƒç½‘æ ¼
    torchvision.utils.save_image(samples, save_path, nrow=nrow, normalize=False)

def evaluate_unconditional(model, config, logger, epoch):
    """è¯„ä¼°æ— æ¡ä»¶ç”Ÿæˆæ¨¡å‹"""
    logger.log(f"å¼€å§‹è¯„ä¼°æ— æ¡ä»¶ç”Ÿæˆæ¨¡å‹ (Epoch {epoch})")
    
    # ç”Ÿæˆæ ·æœ¬
    with torch.no_grad():
        samples = model.sample(config.sample_size)
    
    # ä¿å­˜æ ·æœ¬
    save_dir = os.path.join(config.output_dir, "samples")
    save_path = os.path.join(save_dir, f"epoch_{epoch}_samples.png")
    save_samples(samples, save_path)
    
    logger.log(f"æ ·æœ¬å·²ä¿å­˜åˆ°: {save_path}")
    
    # è®¡ç®—FIDï¼ˆå¦‚æœæœ‰è¶³å¤Ÿçš„æ ·æœ¬ï¼‰
    if epoch > 0 and epoch % config.eval_interval == 0:
        try:
            # ç”Ÿæˆæ›´å¤šæ ·æœ¬ç”¨äºFIDè®¡ç®—
            all_samples = []
            num_batches = 100 // config.sample_size + 1
            
            for _ in range(num_batches):
                batch_samples = model.sample(config.sample_size)
                all_samples.append(batch_samples)
            
            all_samples = torch.cat(all_samples, dim=0)[:100]  # å–å‰100ä¸ªæ ·æœ¬
            
            # ä¿å­˜ç”¨äºFIDè®¡ç®—çš„æ ·æœ¬
            fid_dir = os.path.join(config.output_dir, "fid_samples")
            os.makedirs(fid_dir, exist_ok=True)
            
            for i, sample in enumerate(all_samples):
                sample_path = os.path.join(fid_dir, f"sample_{i:03d}.png")
                torchvision.utils.save_image((sample + 1) / 2, sample_path)
            
            # è®¡ç®—FIDï¼ˆè¿™é‡Œéœ€è¦çœŸå®æ•°æ®é›†è·¯å¾„ï¼‰
            # fid_score = evaluate_generated_images(fid_dir, real_folder=None)
            # logger.log(f"FID Score: {fid_score:.3f}")
            
        except Exception as e:
            logger.log(f"FIDè®¡ç®—å¤±è´¥: {e}")

def evaluate_inpainting(model, test_loader, config, logger, epoch):
    """è¯„ä¼°å›¾åƒä¿®å¤æ¨¡å‹"""
    logger.log(f"å¼€å§‹è¯„ä¼°å›¾åƒä¿®å¤æ¨¡å‹ (Epoch {epoch})")
    
    total_psnr = 0
    total_ssim = 0
    num_samples = 0
    
    with torch.no_grad():
        for i, (images, _) in enumerate(test_loader):
            if i >= 10:  # åªè¯„ä¼°å‰10ä¸ªbatch
                break
                
            images = images.to(config.device)
            
            # åˆ›å»ºä¸åŒç±»å‹çš„é®ç½©
            for mask_type in ["center", "random"]:
                mask = model.create_mask(images.shape, mask_type, 0.5)
                masked_images = images * mask
                
                # ä¿®å¤å›¾åƒ
                restored = model.inpaint_improved(images, mask, num_samples=1)
                
                # è®¡ç®—PSNRå’ŒSSIM
                for j in range(images.shape[0]):
                    # åªåœ¨é®ç½©åŒºåŸŸè®¡ç®—æŒ‡æ ‡
                    mask_region = (1 - mask[j]).bool()
                    
                    if mask_region.sum() > 0:
                        original_patch = images[j][mask_region].cpu().numpy()
                        restored_patch = restored[0][j][mask_region].cpu().numpy()
                        
                        psnr = psnr(original_patch, restored_patch)
                        ssim = ssim(
                            original_patch.reshape(-1), 
                            restored_patch.reshape(-1)
                        )
                        
                        total_psnr += psnr
                        total_ssim += ssim
                        num_samples += 1
    
    if num_samples > 0:
        avg_psnr = total_psnr / num_samples
        avg_ssim = total_ssim / num_samples
        
        logger.log(f"å¹³å‡PSNR: {avg_psnr:.3f}")
        logger.log(f"å¹³å‡SSIM: {avg_ssim:.3f}")
        
        return {"PSNR": avg_psnr, "SSIM": avg_ssim}
    
    return {}

def train_model(task, config_name=None):
    """è®­ç»ƒæ¨¡å‹ä¸»å‡½æ•°"""
    # è·å–é…ç½®
    config = get_config(task)
    if config_name:
        # å¯ä»¥æ ¹æ®config_nameè¿›ä¸€æ­¥å®šåˆ¶é…ç½®
        pass
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(config.seed)
    np.random.seed(config.seed)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_name = f"{task}_{timestamp}"
    config.output_dir = os.path.join("experiments", experiment_name)
    os.makedirs(config.output_dir, exist_ok=True)
    
    # åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
    logger = ExperimentLogger(config.output_dir)
    logger.log(f"å¼€å§‹è®­ç»ƒä»»åŠ¡: {task}")
    logger.log(f"é…ç½®: {vars(config)}")
    
    # ä¿å­˜é…ç½®
    config_path = os.path.join(config.output_dir, "config.json")
    with open(config_path, "w", encoding="utf-8") as f:
        json.dump(vars(config), f, indent=2, ensure_ascii=False, default=str)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    if task in ["cifar10", "conditional"]:
        train_loader = DataLoaderFactory.get_cifar10_loader(config)
        test_loader = DataLoaderFactory.get_test_loader(config)
    else:
        # åˆ›å»ºè™šæ‹Ÿæ•°æ®åŠ è½½å™¨
        class DummyDataLoader:
            def __init__(self, config):
                self.batch_size = config.batch_size
                self.config = config
            def __iter__(self):
                for i in range(100):  # 100ä¸ªbatch
                    fake_data = torch.randn(self.batch_size, 3, self.config.image_size, self.config.image_size)
                    fake_labels = torch.randint(0, 10, (self.batch_size,))
                    yield fake_data, fake_labels
        
        train_loader = DummyDataLoader(config)
        test_loader = DummyDataLoader(config)
    
    # åˆ›å»ºæ¨¡å‹
    if task == "inpainting":
        model = InpaintDDPM(
            train_loader, 
            T=config.T, 
            device=config.device,
            output_dir=config.output_dir
        )
    elif task == "conditional":
        model = ConditionalDDPM_Model(
            train_loader,
            T=config.T,
            num_classes=config.num_classes,
            device=config.device
        )
    else:  # unconditional
        model = DDPM_Model(
            train_loader,
            T=config.T,
            device=config.device
        )
    
    logger.log(f"æ¨¡å‹å·²åˆ›å»ºï¼Œå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
    
    # è®­ç»ƒå¾ªç¯
    model.train()
    for epoch in range(config.num_epochs):
        logger.log(f"å¼€å§‹è®­ç»ƒ Epoch {epoch+1}/{config.num_epochs}")
        
        if hasattr(model, 'train_epoch'):
            # å¦‚æœæ¨¡å‹æœ‰è‡ªå®šä¹‰çš„è®­ç»ƒepochæ–¹æ³•
            epoch_loss = model.train_epoch()
        else:
            # ä½¿ç”¨æ¨¡å‹çš„train_modelæ–¹æ³•ï¼ˆä½†åªè®­ç»ƒä¸€ä¸ªepochï¼‰
            model.train_model(num_epochs=1, lr=config.lr)
            epoch_loss = 0.0  # å ä½ç¬¦
        
        logger.log(f"Epoch {epoch+1} å®Œæˆï¼ŒæŸå¤±: {epoch_loss:.4f}")
        
        # å®šæœŸè¯„ä¼°
        if (epoch + 1) % config.eval_interval == 0:
            model.eval()
            
            if task == "inpainting":
                metrics = evaluate_inpainting(model, test_loader, config, logger, epoch+1)
            else:
                evaluate_unconditional(model, config, logger, epoch+1)
                metrics = {}
            
            logger.save_metrics(epoch+1, metrics)
            model.train()
        
        # å®šæœŸä¿å­˜æ¨¡å‹
        if (epoch + 1) % config.save_interval == 0:
            model_path = os.path.join(config.output_dir, f"model_epoch_{epoch+1}.pth")
            torch.save(model.state_dict(), model_path)
            logger.log(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = os.path.join(config.output_dir, "final_model.pth")
    torch.save(model.state_dict(), final_model_path)
    logger.log(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ°: {final_model_path}")
    
    logger.log("è®­ç»ƒå®Œæˆï¼")
    return config.output_dir

def main():
    parser = argparse.ArgumentParser(description="DDPMè®­ç»ƒå’Œè¯„ä¼°è„šæœ¬")
    parser.add_argument("--task", type=str, default="cifar10",
                       choices=["cifar10", "inpainting", "conditional", "super_resolution"],
                       help="é€‰æ‹©ä»»åŠ¡ç±»å‹")
    parser.add_argument("--config", type=str, default=None,
                       help="è‡ªå®šä¹‰é…ç½®åç§°")
    parser.add_argument("--eval_only", action="store_true",
                       help="ä»…è¯„ä¼°æ¨¡å¼")
    parser.add_argument("--model_path", type=str, default=None,
                       help="é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„")
    
    args = parser.parse_args()
    
    if args.eval_only:
        print("ä»…è¯„ä¼°æ¨¡å¼æš‚æœªå®ç°")
        return
    
    # å¼€å§‹è®­ç»ƒ
    experiment_dir = train_model(args.task, args.config)
    print(f"\nğŸ‰ å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {experiment_dir}")

if __name__ == "__main__":
    main() 